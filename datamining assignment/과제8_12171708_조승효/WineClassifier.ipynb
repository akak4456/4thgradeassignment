{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WindClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3rsyN-78ocI6",
        "outputId": "518b97ef-cb2e-4f1b-c26d-7e31f74f1b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AH7bAAGcobV3"
      },
      "source": [
        "# 와인 감별사 : 와인의 Quality를 분류하는 Classifier 만들기\n",
        "\n",
        "## 1. 과제 설명\n",
        "이번 과제에서는 케라스(Keras)를 활용하여, 와인의 품질을 분류하는 인공신경망 분류기를 만들어 볼 것입니다.\n",
        "케라스는 Tensorflow, Theano 등의 딥 러닝 라이브러리 위에서 동작하는 오픈 소스 라이브러리로, 보다 쉬운 API를 제공함으로써 모델 설계 및 학습, 테스트가 간단하다는 장점이 있습니다. \n",
        "\n",
        "### 1.1 케라스 설치를 위한 필수 라이브러리\n",
        "케라스를 설치하기 전에 먼저 필수적으로 설치해야 할 것들이 있습니다.\n",
        "* Anaconda : Python 3.x 버전, Numpy, Pandas, SciPy, sklearn 등 필수 라이브러리들이 포함된 통합 배포 팩\n",
        "<br> 아나콘다 설치 : https://www.anaconda.com/distribution/#download-section\n",
        "* Tensorflow : Google에서 개발한 오픈 소스 딥 러닝 라이브러리. <b>설치된 Python 버전과 호환되는 것으로 설치할것!</b>\n",
        "<br> 텐서플로우 설치 : https://www.tensorflow.org/install/pip\n",
        "<br> * CPU 버전을 설치할 것을 권장. \n",
        "\n",
        "### 1.2 케라스 설치\n",
        "위 라이브러리들을 설치한 후, 케라스를 설치합니다.\n",
        "* https://keras.io/#installation\n",
        "\n",
        "### 1.3 케라스 설치 확인\n",
        "케라스가 올바르게 설치되었는지 확인하기 위해, 케라스를 Import한 뒤 버전을 출력해봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RdWzUjvZobV4",
        "outputId": "038c68ed-71f8-4ded-9041-acaee9b53a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import keras\n",
        "\n",
        "keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lWlwSKksobV_"
      },
      "source": [
        "위와 같이 케라스의 버전이 출력되면 정상입니다. (출력되는 버전은 위 예시와 다를 수도 있음)<br> 나중에 신경망을 만들기 위한 클래스들도 함께 Import 합시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ruFtS02AobWA",
        "colab": {}
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZggQC1JiobWC"
      },
      "source": [
        "---\n",
        "## 2. Data Set 설명\n",
        " 본 과제에서 사용할 데이터 셋은 UCI에서 제공되는 Wine Quality Data Set입니다. (https://archive.ics.uci.edu/ml/datasets/Wine+Quality) 데이터는 레드 와인 1599개, 화이트 와인 4898개의 화학적 특성을 포함하고 있습니다. 데이터는 두 개의 CSV(Comma-seperated values)형태로 제공되며, 구성은 다음과 같습니다.\n",
        "* 화이트 와인 / 레드 와인 CSV 파일\n",
        "* 11개의 실수(Real) 입력 변수 (X)\n",
        "    * fixed acidity\n",
        "    * volatile acidity\n",
        "    * citric acid\n",
        "    * residual sugar\n",
        "    * chlorides\n",
        "    * free sulfur dioxide\n",
        "    * total sulfur dioxide\n",
        "    * density\n",
        "    * pH\n",
        "    * sulphates\n",
        "    * alcohol\n",
        "* 1개의 클래스 레이블 (Y)\n",
        "   * quality (0~10, 0: Very poor, 10: Very excellent)\n",
        "* Missing Value 없음\n",
        "* 클래스들이 불균등하게 분포함.\n",
        "\n",
        "더 자세한 사항은 블랙보드에 함께 올라가있는 설명 파일을 참고하도록 합시다.\n",
        "\n",
        "### 2.1 데이터 로드\n",
        "데이터 분석에서 가장 많이 사용되는 라이브러리 중 하나인 Pandas와 Numpy를 Import하겠습니다. Pandas는 데이터 분석에 유용한 데이터 타입인 DataFrame을 제공하며, Numpy는 효율적이고 빠른 매트릭스 연산을 지원합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j5kTZyX1obWD",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.__version__\n",
        "pd.options.display.max_rows=15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G0thM0X0obWG",
        "outputId": "7a55a4d9-2d34-47c8-91fb-f8eb74727caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "np.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.18.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fHEmT15sobWJ"
      },
      "source": [
        "Pandas를 이용해서 CSV 파일을 읽어들이도록 합시다. white_wine 변수에는 화이트 와인 데이터를, red_wine 변수에는 레드 와인 데이터를 읽어들입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t0s-aG2SobWJ",
        "colab": {}
      },
      "source": [
        "#########################코드########################\n",
        "\n",
        "\n",
        "white_wine = pd.read_csv('/gdrive/My Drive/winequality-white.csv',header='infer')\n",
        "red_wine = pd.read_csv('/gdrive/My Drive/winequality-red.csv',header='infer')\n",
        "\n",
        "\n",
        "#####################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E3zUEFZtobWM"
      },
      "source": [
        "### 2.2 데이터 전처리\n",
        "데이터를 읽어들인 뒤, 읽어들인 데이터프레임을 display 함수를 통해 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IR2Bk48fobWM",
        "outputId": "5e54f546-509e-49bc-bab7-ca90ba99d4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "display(white_wine)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.00100</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.99400</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.99510</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.99560</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.99560</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4893</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4895</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4898 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0               7.0              0.27         0.36  ...       0.45      8.8        6\n",
              "1               6.3              0.30         0.34  ...       0.49      9.5        6\n",
              "2               8.1              0.28         0.40  ...       0.44     10.1        6\n",
              "3               7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "4               7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "...             ...               ...          ...  ...        ...      ...      ...\n",
              "4893            6.2              0.21         0.29  ...       0.50     11.2        6\n",
              "4894            6.6              0.32         0.36  ...       0.46      9.6        5\n",
              "4895            6.5              0.24         0.19  ...       0.46      9.4        6\n",
              "4896            5.5              0.29         0.30  ...       0.38     12.8        7\n",
              "4897            6.0              0.21         0.38  ...       0.32     11.8        6\n",
              "\n",
              "[4898 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aoIonV7KobWP",
        "outputId": "c08b4b4d-2706-4a74-90f0-0da50ad47ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "display(red_wine)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11</td>\n",
              "      <td>34</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25</td>\n",
              "      <td>67</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17</td>\n",
              "      <td>60</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11</td>\n",
              "      <td>34</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32</td>\n",
              "      <td>44</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39</td>\n",
              "      <td>51</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29</td>\n",
              "      <td>40</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32</td>\n",
              "      <td>44</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18</td>\n",
              "      <td>42</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "1               7.8             0.880         0.00  ...       0.68      9.8        5\n",
              "2               7.8             0.760         0.04  ...       0.65      9.8        5\n",
              "3              11.2             0.280         0.56  ...       0.58      9.8        6\n",
              "4               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "...             ...               ...          ...  ...        ...      ...      ...\n",
              "1594            6.2             0.600         0.08  ...       0.58     10.5        5\n",
              "1595            5.9             0.550         0.10  ...       0.76     11.2        6\n",
              "1596            6.3             0.510         0.13  ...       0.75     11.0        6\n",
              "1597            5.9             0.645         0.12  ...       0.71     10.2        5\n",
              "1598            6.0             0.310         0.47  ...       0.66     11.0        6\n",
              "\n",
              "[1599 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YA0L1jCDobWS"
      },
      "source": [
        "이제 데이터프레임을 입력 변수와 정답 셋(클래스 레이블)으로 나누는 함수를 작성하겠습니다.<br>\n",
        "<b>generate_data</b>함수는 데이터프레임 객체와 테스트 셋 비율을 입력으로 받아, 네 개의 numpy array를 반환합니다. 트레이닝 셋과 테스트 셋의 비율은 training_set_ratio에 의해 결정됩니다.\n",
        "* Function : generate_data\n",
        " * 입력\n",
        "     * pd.DataFrame : df\n",
        "     * double : training_set_ratio  \n",
        " * 출력\n",
        "     * np.array : X_train\n",
        "     * np.array : Y_train\n",
        "     * np.array : X_test\n",
        "     * np.array : Y_test\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sHHRgjpWobWT",
        "colab": {}
      },
      "source": [
        "#####################################################\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(df, t_r):\n",
        "    data = df.iloc[:,0:11]\n",
        "    target = df.iloc[:,11:]\n",
        "    target = target.values.reshape((target.shape[0],))\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=(1-t_r), shuffle=True, stratify=target, random_state=34)\n",
        "    return X_train.values, Y_train, X_test.values, Y_test\n",
        "#####################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A-kAXFUkobWV",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = generate_data(white_wine, 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN8ZcGqjcs4f",
        "colab_type": "code",
        "outputId": "ab9809a6-36fa-4e99-dacf-f2d610c70159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3428, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9ZPalH-L0Mj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "2fa978c5-48e9-4c0b-d6e2-ceecf43819b0"
      },
      "source": [
        "white_wine.info()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4898 entries, 0 to 4897\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         4898 non-null   float64\n",
            " 1   volatile acidity      4898 non-null   float64\n",
            " 2   citric acid           4898 non-null   float64\n",
            " 3   residual sugar        4898 non-null   float64\n",
            " 4   chlorides             4898 non-null   float64\n",
            " 5   free sulfur dioxide   4898 non-null   float64\n",
            " 6   total sulfur dioxide  4898 non-null   float64\n",
            " 7   density               4898 non-null   float64\n",
            " 8   pH                    4898 non-null   float64\n",
            " 9   sulphates             4898 non-null   float64\n",
            " 10  alcohol               4898 non-null   float64\n",
            " 11  quality               4898 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 459.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUab75slblJA",
        "colab_type": "code",
        "outputId": "4f914f74-8d5b-48bf-c54e-5a16f000736f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "display(y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([7, 6, 5, ..., 7, 8, 6])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzzAeXKgdLnw",
        "colab_type": "code",
        "outputId": "0a312813-18da-42f9-90eb-439384d4c54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3428,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ctr0KTQ7obWX"
      },
      "source": [
        "작성한 함수를 호출하여 화이트 와인 데이터에 대해 트레이닝 셋과 테스트 셋의 입력과 정답이 적절하게 생성되었는지 확인합니다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FWOKgPSaobWY"
      },
      "source": [
        "# 3. 케라스를 이용한 모델 생성, 학습, 테스트\n",
        "입력 데이터와 정답 셋이 만들어졌으니 케라스를 사용하여 각 데이터에 대한 분류기를 생성하고, 트레이닝 셋으로 학습시킨 뒤 테스트 정확도를 관찰합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FO4OxZuhobWZ"
      },
      "source": [
        "# 과제\n",
        "### 1. 화이트 와인 분류 모델과 레드 와인 분류 모델 설계 및 학습\n",
        "* 하나의 히든 레이어에 32개의 노드를 가진 인공신경망 모델 생성 및 모델 학습\n",
        "* 트레이닝 Epoch에 따라 Loss의 변화를 그래프로 시각화\n",
        "* 테스트 셋에 대한 정확도 기록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBUuMAxu5xgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "white_x_train,white_y_train,white_x_test,white_y_test = generate_data(white_wine, 0.7)\n",
        "red_x_train,red_y_train,red_x_test,red_y_test = generate_data(red_wine, 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmRf2ouPcUUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gE8UhHrNobWZ",
        "colab": {}
      },
      "source": [
        "##########################################################\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(units=32,input_dim=11,activation='relu'))\n",
        "model.add(layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "###########################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCzyK5mpp8YD",
        "colab_type": "code",
        "outputId": "9ee8dd26-9b5a-46a3-8215-e3be7792464e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_54 (Dense)             (None, 32)                384       \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 714\n",
            "Trainable params: 714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUDkHOrQV26c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-hIEkILc8So",
        "colab_type": "code",
        "outputId": "07f96400-d565-497f-df2e-0d63d453234c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#white_wine에 대한 train\n",
        "history = model.fit(white_x_train, white_y_train, batch_size = 10, epochs = 100)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['loss'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 5.9946 - accuracy: 0.4005\n",
            "Epoch 2/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.6292 - accuracy: 0.4487\n",
            "Epoch 3/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.3936 - accuracy: 0.4562\n",
            "Epoch 4/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2815 - accuracy: 0.4656\n",
            "Epoch 5/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2777 - accuracy: 0.4595\n",
            "Epoch 6/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2548 - accuracy: 0.4597\n",
            "Epoch 7/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2553 - accuracy: 0.4729\n",
            "Epoch 8/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2300 - accuracy: 0.4813\n",
            "Epoch 9/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2367 - accuracy: 0.4726\n",
            "Epoch 10/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2291 - accuracy: 0.4781\n",
            "Epoch 11/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2161 - accuracy: 0.4749\n",
            "Epoch 12/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2118 - accuracy: 0.4807\n",
            "Epoch 13/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1967 - accuracy: 0.4907\n",
            "Epoch 14/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1949 - accuracy: 0.4845\n",
            "Epoch 15/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1972 - accuracy: 0.4816\n",
            "Epoch 16/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1907 - accuracy: 0.5044\n",
            "Epoch 17/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2024 - accuracy: 0.4775\n",
            "Epoch 18/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1844 - accuracy: 0.4883\n",
            "Epoch 19/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.2054 - accuracy: 0.4866\n",
            "Epoch 20/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1714 - accuracy: 0.4939\n",
            "Epoch 21/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1722 - accuracy: 0.4875\n",
            "Epoch 22/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1709 - accuracy: 0.4927\n",
            "Epoch 23/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1676 - accuracy: 0.4968\n",
            "Epoch 24/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1636 - accuracy: 0.4901\n",
            "Epoch 25/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1746 - accuracy: 0.4883\n",
            "Epoch 26/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1584 - accuracy: 0.4959\n",
            "Epoch 27/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1469 - accuracy: 0.5050\n",
            "Epoch 28/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1628 - accuracy: 0.5038\n",
            "Epoch 29/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1760 - accuracy: 0.4956\n",
            "Epoch 30/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1523 - accuracy: 0.4977\n",
            "Epoch 31/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1592 - accuracy: 0.5012\n",
            "Epoch 32/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1478 - accuracy: 0.5090\n",
            "Epoch 33/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1525 - accuracy: 0.5053\n",
            "Epoch 34/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1739 - accuracy: 0.4927\n",
            "Epoch 35/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1479 - accuracy: 0.4962\n",
            "Epoch 36/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1602 - accuracy: 0.5009\n",
            "Epoch 37/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1416 - accuracy: 0.4962\n",
            "Epoch 38/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1381 - accuracy: 0.5020\n",
            "Epoch 39/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1526 - accuracy: 0.4982\n",
            "Epoch 40/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1423 - accuracy: 0.5102\n",
            "Epoch 41/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1432 - accuracy: 0.5061\n",
            "Epoch 42/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1427 - accuracy: 0.5067\n",
            "Epoch 43/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1380 - accuracy: 0.5120\n",
            "Epoch 44/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1608 - accuracy: 0.4819\n",
            "Epoch 45/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1431 - accuracy: 0.5058\n",
            "Epoch 46/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1355 - accuracy: 0.5088\n",
            "Epoch 47/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1284 - accuracy: 0.5163\n",
            "Epoch 48/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1263 - accuracy: 0.5029\n",
            "Epoch 49/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1234 - accuracy: 0.5053\n",
            "Epoch 50/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1297 - accuracy: 0.5020\n",
            "Epoch 51/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1367 - accuracy: 0.5085\n",
            "Epoch 52/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1276 - accuracy: 0.5111\n",
            "Epoch 53/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1206 - accuracy: 0.5128\n",
            "Epoch 54/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1150 - accuracy: 0.5134\n",
            "Epoch 55/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1221 - accuracy: 0.5201\n",
            "Epoch 56/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1162 - accuracy: 0.5204\n",
            "Epoch 57/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1228 - accuracy: 0.5088\n",
            "Epoch 58/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1167 - accuracy: 0.5079\n",
            "Epoch 59/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1339 - accuracy: 0.5067\n",
            "Epoch 60/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1136 - accuracy: 0.5123\n",
            "Epoch 61/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1208 - accuracy: 0.5053\n",
            "Epoch 62/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1162 - accuracy: 0.5222\n",
            "Epoch 63/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1151 - accuracy: 0.5102\n",
            "Epoch 64/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1203 - accuracy: 0.5050\n",
            "Epoch 65/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1181 - accuracy: 0.5146\n",
            "Epoch 66/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1048 - accuracy: 0.5137\n",
            "Epoch 67/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1163 - accuracy: 0.5184\n",
            "Epoch 68/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1113 - accuracy: 0.5204\n",
            "Epoch 69/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1137 - accuracy: 0.5175\n",
            "Epoch 70/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1106 - accuracy: 0.5120\n",
            "Epoch 71/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1192 - accuracy: 0.5111\n",
            "Epoch 72/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1133 - accuracy: 0.5160\n",
            "Epoch 73/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1014 - accuracy: 0.5303\n",
            "Epoch 74/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1091 - accuracy: 0.5213\n",
            "Epoch 75/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1029 - accuracy: 0.5175\n",
            "Epoch 76/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1328 - accuracy: 0.5041\n",
            "Epoch 77/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1009 - accuracy: 0.5277\n",
            "Epoch 78/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1145 - accuracy: 0.5123\n",
            "Epoch 79/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1041 - accuracy: 0.5257\n",
            "Epoch 80/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1063 - accuracy: 0.5149\n",
            "Epoch 81/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0976 - accuracy: 0.5213\n",
            "Epoch 82/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1056 - accuracy: 0.5216\n",
            "Epoch 83/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0996 - accuracy: 0.5280\n",
            "Epoch 84/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0867 - accuracy: 0.5254\n",
            "Epoch 85/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0965 - accuracy: 0.5236\n",
            "Epoch 86/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0968 - accuracy: 0.5172\n",
            "Epoch 87/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0983 - accuracy: 0.5324\n",
            "Epoch 88/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0951 - accuracy: 0.5306\n",
            "Epoch 89/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0931 - accuracy: 0.5198\n",
            "Epoch 90/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0913 - accuracy: 0.5330\n",
            "Epoch 91/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0960 - accuracy: 0.5222\n",
            "Epoch 92/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0910 - accuracy: 0.5201\n",
            "Epoch 93/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0888 - accuracy: 0.5228\n",
            "Epoch 94/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.1000 - accuracy: 0.5195\n",
            "Epoch 95/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0877 - accuracy: 0.5239\n",
            "Epoch 96/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0878 - accuracy: 0.5268\n",
            "Epoch 97/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0835 - accuracy: 0.5359\n",
            "Epoch 98/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0930 - accuracy: 0.5201\n",
            "Epoch 99/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0891 - accuracy: 0.5251\n",
            "Epoch 100/100\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 1.0874 - accuracy: 0.5292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAbIUlEQVR4nO3da3Bc5Z3n8e//nL5Ial2sm+8G2UDCxSyGFSQUE2eXkADJDJtsUltDzW4GMglvZrOZzVRmk+LFVKpSlZpkK5ns1GyyVEKGzCYZMgyzy5IFlmXIEjIMIBsbDDZgjC8SNmpZlqXWpa/PvjindfEFtS8tPZZ+nyqV1a2j7udwxO88/T/P8xxzziEiIv4KFrsBIiLy3hTUIiKeU1CLiHhOQS0i4jkFtYiI5xL1eNGuri7X09NTj5cWEVmStm3bNuSc6z7Vz+oS1D09PfT19dXjpUVEliQzO3C6n6n0ISLiOQW1iIjnFNQiIp6rS436VIrFIv39/UxNTS3UWy6IhoYG1q9fTzKZXOymiMgStWBB3d/fT0tLCz09PZjZQr1tXTnnOHr0KP39/WzcuHGxmyMiS1RNpQ8zW2FmD5nZHjPbbWY3nukbTU1N0dnZuWRCGsDM6OzsXHKfEkTEL7X2qL8HPO6c+4yZpYCms3mzpRTSVUtxn0TEL/P2qM2sDdgK/AjAOVdwzo3UozHvjk4xNlWsx0uLiFywail9bASywI/N7CUz+6GZZU7cyMzuMbM+M+vLZrNn1ZjsWJ7cVOmsfrcWzc3NdXttEZF6qSWoE8B1wPedc9cC48BXT9zIOXefc67XOdfb3X3KWZDzMgPdxkBEZK5agrof6HfOPR8/fogouM87w1iIG8445/jKV77C5s2bufrqq3nwwQcBOHz4MFu3bmXLli1s3ryZX//615TLZe66667pbb/73e/Wv4EiIrPMezHROXfEzA6Z2fudc68DHwFeO5c3/fr/epXX3hk96fmJQpkwMNKJM5+Hc+XaVv70d66qaduHH36YHTt2sHPnToaGhrj++uvZunUrP/vZz7j11lu59957KZfLTExMsGPHDgYGBti1axcAIyN1Kc+LiJxWraM+vgj8NB7xsQ+4u35Nqr9nn32WO++8kzAMWbVqFR/+8Id58cUXuf766/nc5z5HsVjkk5/8JFu2bGHTpk3s27ePL37xi3ziE5/gYx/72GI3X0SWmZqC2jm3A+g9X296up7vniOjZFIJNnSc1ei/c7Z161aeeeYZfvnLX3LXXXfx5S9/mc9+9rPs3LmTJ554gh/84Af84he/4P7771+U9onI8uTVWh8LVaP+0Ic+xIMPPki5XCabzfLMM89www03cODAAVatWsUXvvAFPv/5z7N9+3aGhoaoVCp8+tOf5hvf+Abbt2+vfwNFRGZZsCnktTDALcC4j0996lM899xzXHPNNZgZ3/rWt1i9ejUPPPAA3/72t0kmkzQ3N/OTn/yEgYEB7r77biqVCgDf/OY3694+EZHZzNWhC9vb2+tOvHHA7t27ueKKK97z9954d4xUGNDTddIwba/Vsm8iIu/FzLY5505ZYvas9KFx1CIiJ/IrqM2oRw9fRORCtqBBPV8IX4jLG+nEIiL1tmBB3dDQwNGjR9872IwFGfVxvlTXo25oaFjspojIErZgoz7Wr19Pf38/77Vg01AuT8VB4Wh6oZp1zqp3eBERqZcFC+pkMjnvXVDu+vELDI8XeOTfb1mgVomI+M+ri4mJIKBYvoBqHyIiC8CzoDbK8cQSERGJ+BXUoVGqqEctIjKbX0EdGCWVPkRE5vArqMOAsnrUIiJz+BXUgVEsq0YtIjKbX0EdmnrUIiIn8Cuog0A9ahGRE3gW1OpRi4icyKugDkOjqKAWEZnDq6BOBhr1ISJyIq+COoxLH1o6VERkhldBnQyjFak1O1FEZIZXQR0GUXM0O1FEZIZXQT3To9YQPRGRKq+COgzioFaPWkRkmldBnQhUoxYROZFfQR3GNWqVPkREpnkV1Cp9iIiczKug1vA8EZGTeRXU1eF5uh2XiMgMr4I6GZc+dINbEZEZiVo2MrP9wBhQBkrOud56NKZao9Z6HyIiM2oK6ti/dM4N1a0lQDIe9aE1qUVEZnhV+lCPWkTkZLUGtQP+j5ltM7N7TrWBmd1jZn1m1pfNZs+qMQmN+hAROUmtQf1bzrnrgNuBPzSzrSdu4Jy7zznX65zr7e7uPqvGJLQok4jISWoKaufcQPzvIPD3wA31aExCizKJiJxk3qA2s4yZtVS/Bz4G7KpHYxKamSgicpJaRn2sAv7ezKrb/8w593hdGlMtfahGLSIybd6gds7tA65ZgLao9CEicgpeDc9LaHieiMhJPAvq6oQXBbWISJVfQR1We9QqfYiIVPkV1FqUSUTkJH4FdVhd5lRBLSJS5VVQh9M9apU+RESqvArqZKhRHyIiJ/IqqEPdhVxE5CReBbUWZRIROZlXQR0GhplmJoqIzOZVUEM0RE+lDxGRGR4GdUBJoz5ERKZ5GNTqUYuIzOZfUIemi4kiIrN4F9RhEKhHLSIyi3dBnQxNNWoRkVm8C+owMM1MFBGZxbugToYBRQW1iMg074I66lGr9CEiUuVdUCcCjfoQEZnNv6AONY5aRGQ2/4Jaw/NERObwMKg1PE9EZDb/glqlDxGROfwLai3KJCIyh39BHWrCi4jIbP4FdWAUNTxPRGSah0EdqEctIjKLd0EdhkZRMxNFRKZ5F9QJLcokIjKHh0EdaAq5iMgsNQe1mYVm9pKZPVrPBkW34lLpQ0Sk6kx61F8CdterIVW6FZeIyFw1BbWZrQc+Afywvs3RzW1FRE5Ua4/6z4E/Aepek0iEmpkoIjLbvEFtZr8NDDrnts2z3T1m1mdmfdls9qwbpB61iMhctfSobwLuMLP9wN8AN5vZfz9xI+fcfc65Xudcb3d391k3SIsyiYjMNW9QO+e+5pxb75zrAX4X+Afn3L+tV4PCeGaicwprERHwcBx1MjAA9apFRGKJM9nYOfcr4Fd1aUksDKOgLlccybCe7yQicmHwsEcdNamokR8iIoCHQR0GMz1qERHxMKiTcelDa1KLiES8C+owLn2oRy0iEvEuqBNhddSHatQiIuBjUFeH56n0ISIC+BjUYdQkjaMWEYn4F9SBSh8iIrP5G9QqfYiIAD4Gdagp5CIis3kX1DPD81T6EBEBD4O6uiiTJryIiES8C2pNIRcRmcu7oK4Oz9OiTCIiEf+CWj1qEZE5/AtqLcokIjKHf0GtRZlERObwL6i1KJOIyBz+BbVmJoqIzOFfUE8vyqQetYgI+BjUugu5iMgc/ga1Sh8iIoCXQa31qEVEZvMvqKujPjQzUUQE8DCoQ9WoRUTm8C6ok9VRH6pRi4gAHgZ13KHWetQiIjHvgtrMSIZGUaUPERHAw6CGqE6ttT5ERCJeBnUyCFSjFhGJeRnUYWiaQi4iEvMyqBNBoOF5IiKxeYPazBrM7AUz22lmr5rZ1+vdqERgmvAiIhJL1LBNHrjZOZczsyTwrJk95pz7p3o1KgxMPWoRkdi8Qe2cc0AufpiMv+qaosnQdDFRRCRWU43azEIz2wEMAk86554/xTb3mFmfmfVls9lzapSG54mIzKgpqJ1zZefcFmA9cIOZbT7FNvc553qdc73d3d3n1KhkGFBUjVpEBDjDUR/OuRHgaeC2+jQnoh61iMiMWkZ9dJvZivj7RuCjwJ56NioRBppCLiISq2XUxxrgATMLiYL9F865R+vaqMC0KJOISKyWUR8vA9cuQFumJQKjqFEfIiKArzMTQ9WoRUSq/AzqINDMRBGRmKdBrZmJIiJVfga1ZiaKiEzzM6iDQMuciojE/AzqUKUPEZEqL4M6DFT6EBGp8jKokyp9iIhM8zKoQ42jFhGZ5mVQJzUzUURkmpdBHQaBetQiIjEvgzoZmtajFhGJeRnUWo9aRGSGl0FdnUIe3a5RRGR58zOow6hZ6lWLiHga1GFgAJqdKCKCp0GdDBXUIiJVXgZ1GMSlD42lFhHxM6irPeqippGLiPgZ1NUatS4mioh4GtTJuPShSS8iIp4GtXrUIiIzvAzqRLVGrYuJIiKeBnWgCS8iIlV+BvV0j1o1ahERP4NaNWoRkWl+BnW81oduxyUi4mtQV9f60MVEERHPg1qlDxERT4NaizKJiEzzM6jj4XkljfoQEZk/qM1sg5k9bWavmdmrZvalejdK61GLiMxI1LBNCfhj59x2M2sBtpnZk8651+rVqGR11IcuJoqIzN+jds4dds5tj78fA3YD6+rZqJketUofIiJnVKM2sx7gWuD5U/zsHjPrM7O+bDZ7To2avsOLetQiIrUHtZk1A38H/JFzbvTEnzvn7nPO9Trneru7u8+pUVo9T0RkRk1BbWZJopD+qXPu4fo2aWbUh+7wIiJS26gPA34E7HbOfaf+TZoZR60etYhIbT3qm4B/B9xsZjvir4/Xs1GaQi4iMmPe4XnOuWcBW4C2TNOiTCIiMzydmagJLyIiVX4HtUofIiJ+BrWmkIuIzPAyqM2MRGBalElEBE+DGqJetYbniYh4HNTJMKCoGrWIiL9BHfWoVfoQEfE2qJOhUVTpQ0TE36AOA6NYUo9aRMTboN7YleGlQyOL3QwRkUXnbVDfdtVq9g7m2Ds4tthNERFZVP4G9eY1ADz2ypFFbomIyOLyNqhXtzVw7UUrePxVBbWILG/eBjXA7ZtX8+o7oxw8OrHYTRERWTSeB3VU/nj81cOL3BIRkcXjdVBv6GjiqrWtPLZL5Q8RWb68DmqIyh8vHRzh8PHJxW6KiMii8D6oq6M/nlCvWkSWKe+D+tKVzVy+uoW/+sf9TBRKi90cEZEF531QA/zp71zF/qMT/Nljexa7KSIiC+6CCOobL+nk7pt6eOC5A/xm79BiN0dEZEFdEEEN8J9uu5xN3Rm+8rc7GZ0qLnZzREQWTGKxG1CrhmTId/7NFv71f/0Nd/zFs6xrb6QplWBDexM3X76SGzZ2kEpcMOcdEZGamXPnf83n3t5e19fXd95fF+Chbf08svMdxvMlxvMl3h4aJ1+q0JJOcNW6VgzD4WhtSHLLlau49crVtDUl69IWEZHzxcy2Oed6T/mzCy2oTzRZKPObvUM8tedd3nw3R2AGBgPHJhkYmSQRGFetbSWXL3F0vEBuqkRnc4qVLQ2sam3g0pXNvG9VM5etbKE9k6SlIUlzOjF9J3QRkYXwXkF9wZQ+TqcxFXLLlau45cpVc553zvFy/3H+9yuHebn/OOvaG+lqTtOUSjA8nufd0TwHh8f5f28MnnRvRjPY1JXh6nVtXLW2jfZMimRoJIKAsnPki2XypQpNqZDO5jSdmRSjU0X2ZcfZlx2nIRlwfU8H113cDg7+8a0hnnlziHKlwu994GKu2bBiIf8TicgF7oLvUZ+rYrnC/qFx3srmGJ0sMZYvMTJRYPfhMXYNHOfI6NQZvV5jMqRYrlCqOOLOPRUHzenonJjLl7i+p507tqwjGRjl+L9/IjDCICAZGo3JkKZUgqZ0SHM6QSadIBUG9B+b4MDRCd45PsnGzgzXbFjBmrYGzE7u/RfLFQ4cHef1IzneeHeMla1pPnrFKla2NtS8L+P5Ev+07yiDY3luvnwlq87gd0XkzCzp0ke9DY8XGM+XKJYrFMuOMDDSiYBUImA8X2J4vMBQrkAmHXJJdzOrWxuYKpXZcWiEF98+RsU5PnRZF9dsWMFUscyDLx7ix7/Zz8DI+ZkSv7IlzftWtbCxK8NFHU0MjEyys3+E194ZJX+KW5lt2bCCde2NDI3lGcrlSYYBG7sybOzKsKIpyehkidGpInsHc7y4f3j604YZXN/TwQc3dtB/bJK92RxDY3muXt/GBzZ28s8vbqcjk6IpFZIIAt4cHOPVd0bZO5ijvSnJRZ0ZNrQ3kkoEVJyjHDctMDCLTk6tjQlaGpK8fmSMp/a8y9N7BimVHddd3E7vxe1ctbaNVa1pOpvTKk3JkqOg9ky54jh8fJLAbDpwyhVHqewolMtMFStMFMqMF0rTF03zpQpr2hrp6WxidVsDb2XH2XlohJ39I7yVHWdfNsfYVInGZMjV69r4Z+vbuGpdK+9b1cIl3c0cODrBk68d4cndg4xOFulqTtHVnKZQqvD20DgHhycoVRyBQWtjktWtDWx9XzdbL+umuyXNY7sO8+jLh9k7mGN1awOXrMzQ3pRix6ER+o+d/qTT0pBgPF/iTO9TnAiMD2zqoDEZsu3AMY5NzAzJDAw6m9N0N6fpbknT3pQknQhJJox0IqQxGdKQDAgCY2SiyNFcgeHxPEO5AtmxPKNTRbqa06xd0cDaFY2sbGmgqzlFd0uajkyKFY0p2hqTjBdKZGed0DoyKVY0JSmVHUO5PEdzBTDoaErR0ZxiOFdg+8FjbD94jEKpwo2XdHLTpV1curKZ4fHovcfzJZrTSVobo09K0Sep6G9gdLLEyGR0HSUZRp2BhmTIpq4M7ZnU9P6XyhUOH58iERqtDUmaUiFmRrniyJfKhIGRCoPp5wbHpnhnZIpyxdGRSbKiKUV7U6qmk92+bI4H+w7xSv9xbt+8mk9dt37606Fzjly+RHM6ccpPdXJmFNTLgHOOkYkiLQ0JEuGZD1MslivkSxUy8f/0p3uPfKlCQzKc8/zAyCSv9I8wNlViolCmUKqwqTsz3QMulh0DI5McGp6gXHEEgRHG71FxjopzTBXL0735tSsa+dBlXbQ0JKff961sVJ4aHMuTHZ3i3dEoQLO5PCMTRQqlCvlSdO1gqliePjGkEgGdmRQdmSiIu5vTtDYmGcrlGTg2yTsjk2Rz+ZOuU5ytRGBcubaVZBiw49AI5TM9Q51Gd0uaS7ozDOUKHDw6QaE882kpEQduadZ7hUH0KWWyWD5lG1KJgI2dGS5ZmaGtMcngaJ7BsTzjhVJ04smkGJko8sL+YcLA2NDeyP6jEzSnE3zkipVkx/LsOTLG8HiBxmTIRR1NrG9vxAzypQqlsqMjk2JNWwOr2xqYKJQ5MjrF4OgUiSCgPZOiI5NkfXtTdDF/VQuJwDg0PEn/sQmOTxZxDhxQqTiKleg1ISovNqaiE3Iq/nSbDAPS8b+BwVi+xOhkkYlCmUw6QVtjkrbG5PSn4URgDIxMsn9ogoPDE3RmUlyysplLVzbTkp65dGfxJ76qyUKZgZEJpooVMukEmXRUpkzEJ8fgHD7pKahlWXHOUSw7SpUKjcnTn3hmb398sshQLs+xiSLHxgscnyzSnE7Q1RJdLC5XHMPjBY5NFEglAjoy0fMQlceGxwtk0gmuXtdGYyo6kY1NFXl+3zADI5PRSaIlTSaVIJcvMTZVJJcvRZ+kKlEitTYmaGtM0dKQoFSJLlrn8iX2Zcd5/d0x9mVzdDan2dSdYWNnhoqD0akixyeLBAapMJwuLU0WykwUyjSlQtasaGBtWyNhYBybKHBsvMDh41O8lc2xLzvO6FQxHgVVvdge7Y8Z3LFlLZ+5bj3dLWl2HBrhr587wK/eyLKhvZHLV7dycVcTQ2MFDg5PMDAyicF0EA6PF3jn+CRTxeik0pFJsbIlTcU5hseLHJsonLcTWb0kQ5seCTZRKDGUK7zn9itb0rxw7y1n9V7nNOrDzO4HfhsYdM5tPqsWiCwgMyOVMFI1Trw1M1Y0pVjRlJp/41PY0NF0yudb4rH85+ojV5zzS5wX117UzrUXtZ/R7zjnGJ0s0ZAKSCfmfhKrVKJPWq8fGeONwTGcg/XtjVzU0UR7Uyq+GG8EASTDKPwdUa92qlhmshh9eiuUKxRK0TWkYrlCueJobkhMl4XG8yWOTxYZnSqSL85sv6atkZ6uJi7qaOJorsDewRxvZXPTJxZH9AlybKrI2FSJplTI+vbok0NjMmS8UCI3VWKyWJ5+7xP38XyZt0dtZluBHPCTWoNaPWoRkTPzXj3qebsczrlngOHz3ioREanJeVscw8zuMbM+M+vLZrPn62VFRJa98xbUzrn7nHO9zrne7u7u8/WyIiLLnpabExHxnIJaRMRz8wa1mf0ceA54v5n1m9kf1L9ZIiJSNe84aufcnQvREBEROTWVPkREPFeXKeRmlgUOnOWvdwHL7Q62y3GfYXnu93LcZ1ie+32m+3yxc+6UQ+bqEtTnwsz6Tjc7Z6lajvsMy3O/l+M+w/Lc7/O5zyp9iIh4TkEtIuI5H4P6vsVuwCJYjvsMy3O/l+M+w/Lc7/O2z97VqEVEZC4fe9QiIjKLglpExHPeBLWZ3WZmr5vZXjP76mK3p17MbIOZPW1mr5nZq2b2pfj5DjN70szejP89s1tpXADMLDSzl8zs0fjxRjN7Pj7mD5rZ2d1ixWNmtsLMHjKzPWa228xuXOrH2sz+Y/y3vcvMfm5mDUvxWJvZ/WY2aGa7Zj13ymNrkf8S7//LZnbdmbyXF0FtZiHwl8DtwJXAnWZ25eK2qm5KwB87564EPgj8YbyvXwWecs5dBjwVP15qvgTsnvX4z4DvOucuBY4BS3Edme8BjzvnLgeuIdr/JXuszWwd8B+A3viOUCHwuyzNY/1XwG0nPHe6Y3s7cFn8dQ/w/TN6J+fcon8BNwJPzHr8NeBri92uBdr3/wl8FHgdWBM/twZ4fbHbdp73c338h3sz8ChgRLO2Eqf6G1gKX0Ab8DbxRftZzy/ZYw2sAw4BHURrCT0K3LpUjzXQA+ya79gC/w2481Tb1fLlRY+amYNb1R8/t6SZWQ9wLfA8sMo5dzj+0RHg3O+K6pc/B/4EqMSPO4ER51wpfrwUj/lGIAv8OC75/NDMMizhY+2cGwD+M3AQOAwcB7ax9I911emO7TllnC9BveyYWTPwd8AfOedGZ//MRafcJTNu0syqd7HftthtWWAJ4Drg+865a4FxTihzLMFj3Q78K6KT1Fogw8nlgWXhfB5bX4J6ANgw6/H6+LklycySRCH9U+fcw/HT75rZmvjna4DBxWpfHdwE3GFm+4G/ISp/fA9YYWbVpXaX4jHvB/qdc8/Hjx8iCu6lfKxvAd52zmWdc0XgYaLjv9SPddXpju05ZZwvQf0icFl8ZThFdPHhkUVuU12YmQE/AnY7574z60ePAL8ff//7RLXrJcE59zXn3HrnXA/Rsf0H59zvAU8Dn4k3W1L7DOCcOwIcMrP3x099BHiNJXysiUoeHzSzpvhvvbrPS/pYz3K6Y/sI8Nl49McHgeOzSiTzW+xi/Kzi+seBN4C3gHsXuz113M/fIvo49DKwI/76OFHN9ingTeD/Ah2L3dY67f+/AB6Nv98EvADsBf4WSC92++qwv1uAvvh4/w+gfakfa+DrwB5gF/DXQHopHmvg50R1+CLRp6c/ON2xJbp4/pdxvr1CNCqm5vfSFHIREc/5UvoQEZHTUFCLiHhOQS0i4jkFtYiI5xTUIiKeU1CLiHhOQS0i4rn/D/ZIXeErp4XWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6k5t626X8P1",
        "colab_type": "code",
        "outputId": "a1cff587-78e4-4ec7-c6e3-9d824977d3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#white wine에 대한 테스트\n",
        "results = model.evaluate(white_x_test, white_y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 995us/step - loss: 1.1558 - accuracy: 0.5116\n",
            "Test accuracy:  0.5115646123886108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9eCSUL8Pxhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(units=32,input_dim=11,activation='relu'))\n",
        "model.add(layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "###########################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0kAEllBP3Gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "897e4409-6f99-4454-dd57-b953acd68fad"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_56 (Dense)             (None, 32)                384       \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 714\n",
            "Trainable params: 714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls6ciNrtYpQ6",
        "colab_type": "code",
        "outputId": "5752a5e7-d853-46ca-c2f4-4032d942caa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#red_wine에 대한 train\n",
        "history = model.fit(red_x_train, red_y_train, batch_size = 10, epochs = 100)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['loss'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 5.0357 - accuracy: 0.3494\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.2621 - accuracy: 0.4665\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.2215 - accuracy: 0.4924\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1762 - accuracy: 0.5156\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1568 - accuracy: 0.5147\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1460 - accuracy: 0.5103\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1386 - accuracy: 0.5112\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1207 - accuracy: 0.5201\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1232 - accuracy: 0.5308\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1099 - accuracy: 0.5290\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1073 - accuracy: 0.5326\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.1091 - accuracy: 0.5237\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0982 - accuracy: 0.5317\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0903 - accuracy: 0.5398\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0845 - accuracy: 0.5326\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0750 - accuracy: 0.5639\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0708 - accuracy: 0.5398\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0869 - accuracy: 0.5389\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0679 - accuracy: 0.5630\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0616 - accuracy: 0.5567\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0786 - accuracy: 0.5344\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0625 - accuracy: 0.5514\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0396 - accuracy: 0.5523\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0472 - accuracy: 0.5585\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0479 - accuracy: 0.5514\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0379 - accuracy: 0.5648\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0341 - accuracy: 0.5728\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0416 - accuracy: 0.5675\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0326 - accuracy: 0.5621\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0350 - accuracy: 0.5684\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0256 - accuracy: 0.5621\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0271 - accuracy: 0.5585\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0237 - accuracy: 0.5585\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0308 - accuracy: 0.5666\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0430 - accuracy: 0.5541\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0189 - accuracy: 0.5693\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0260 - accuracy: 0.5559\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0278 - accuracy: 0.5657\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0101 - accuracy: 0.5764\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0145 - accuracy: 0.5684\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9996 - accuracy: 0.5728\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9989 - accuracy: 0.5719\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0098 - accuracy: 0.5728\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0063 - accuracy: 0.5782\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0033 - accuracy: 0.5737\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9882 - accuracy: 0.5764\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9973 - accuracy: 0.5657\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9929 - accuracy: 0.5675\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 1.0043 - accuracy: 0.5728\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9858 - accuracy: 0.5719\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9970 - accuracy: 0.5621\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9914 - accuracy: 0.5845\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9964 - accuracy: 0.5710\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9939 - accuracy: 0.5657\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9940 - accuracy: 0.5809\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9763 - accuracy: 0.5907\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9927 - accuracy: 0.5880\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9861 - accuracy: 0.5648\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9695 - accuracy: 0.5943\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9814 - accuracy: 0.5791\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9804 - accuracy: 0.5818\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9820 - accuracy: 0.5764\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9688 - accuracy: 0.5970\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9858 - accuracy: 0.5755\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9845 - accuracy: 0.5800\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9813 - accuracy: 0.5728\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9747 - accuracy: 0.5666\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9673 - accuracy: 0.5800\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9724 - accuracy: 0.5853\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9707 - accuracy: 0.5782\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9575 - accuracy: 0.5800\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9631 - accuracy: 0.5710\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9697 - accuracy: 0.5827\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9586 - accuracy: 0.5782\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9690 - accuracy: 0.5764\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9643 - accuracy: 0.5827\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9678 - accuracy: 0.5746\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9548 - accuracy: 0.5827\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9674 - accuracy: 0.5684\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9581 - accuracy: 0.5809\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9523 - accuracy: 0.5871\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9517 - accuracy: 0.5853\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9611 - accuracy: 0.5746\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9507 - accuracy: 0.5845\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9549 - accuracy: 0.5862\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9617 - accuracy: 0.5764\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9460 - accuracy: 0.5925\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9579 - accuracy: 0.5764\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9538 - accuracy: 0.5782\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9491 - accuracy: 0.5764\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9475 - accuracy: 0.5943\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9448 - accuracy: 0.5746\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9461 - accuracy: 0.5737\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9493 - accuracy: 0.5809\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9498 - accuracy: 0.5916\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9417 - accuracy: 0.5853\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9597 - accuracy: 0.5853\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9513 - accuracy: 0.5898\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9492 - accuracy: 0.5880\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.9479 - accuracy: 0.5836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdQN-XfyYul_",
        "colab_type": "code",
        "outputId": "6df318c4-30fb-49c1-b70c-0317e459adde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#red wine에 대한 테스트\n",
        "results = model.evaluate(red_x_test, red_y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 1ms/step - loss: 0.9589 - accuracy: 0.5917\n",
            "Test accuracy:  0.5916666388511658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5aI6JweqobWc"
      },
      "source": [
        "### 2. 각 모델의 성능을 향상시킬 수 있는 방법 적용\n",
        "* 하이퍼파라미터를 변경하여 테스트 셋에서의 정확도를 향상시킬 것\n",
        "    * 예) 레이어 수, 노드 수, Learning rate 등\n",
        "* 하이퍼파라미터를 변화시킨 각각의 모델에 대해, 트레이닝 Epoch 당 Loss의 변화를 기록하고 이를 시각화\n",
        "* 그 외 성능을 향상시킬 수 있는 모든 방법을 사용하여 가장 성능이 좋은 모델을 선택\n",
        "    * 예) Dropout, Normalization 등"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H5JOT7FBobWc",
        "colab": {}
      },
      "source": [
        "##########################################################\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(units=32,input_dim=11,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "\n",
        "model.add(layers.Dense(units=50,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(units=100,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XUl55C_Y97h",
        "colab_type": "code",
        "outputId": "eeb27af9-c2ae-46b7-bf27-db29527f948b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True,\n",
        "    name='Adam'\n",
        ")\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_62 (Dense)             (None, 32)                384       \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 50)                1650      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 7)                 707       \n",
            "=================================================================\n",
            "Total params: 8,569\n",
            "Trainable params: 8,205\n",
            "Non-trainable params: 364\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "341146bf-14fc-4170-ff8d-14c3af74eb5a",
        "id": "bKGCMB8aZLnq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#white_wine에 대한 train\n",
        "new_white_y_train = white_y_train-3\n",
        "new_white_y_test = white_y_test-3\n",
        "history = model.fit(white_x_train, new_white_y_train, batch_size = 50, epochs = 100,validation_data=(white_x_test, new_white_y_test))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['loss'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 2.6306 - accuracy: 0.2097 - val_loss: 1.8246 - val_accuracy: 0.2993\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0243 - accuracy: 0.3098 - val_loss: 1.4822 - val_accuracy: 0.4327\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7741 - accuracy: 0.3667 - val_loss: 1.3696 - val_accuracy: 0.4435\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5563 - accuracy: 0.4119 - val_loss: 1.2804 - val_accuracy: 0.4463\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4597 - accuracy: 0.4227 - val_loss: 1.2450 - val_accuracy: 0.4510\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3992 - accuracy: 0.4265 - val_loss: 1.2100 - val_accuracy: 0.4517\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3465 - accuracy: 0.4329 - val_loss: 1.1965 - val_accuracy: 0.4531\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3115 - accuracy: 0.4419 - val_loss: 1.1839 - val_accuracy: 0.4531\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2748 - accuracy: 0.4513 - val_loss: 1.2718 - val_accuracy: 0.4374\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2390 - accuracy: 0.4691 - val_loss: 1.1556 - val_accuracy: 0.4837\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2343 - accuracy: 0.4708 - val_loss: 1.2022 - val_accuracy: 0.4633\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1994 - accuracy: 0.4860 - val_loss: 1.2007 - val_accuracy: 0.4599\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2065 - accuracy: 0.4775 - val_loss: 1.1359 - val_accuracy: 0.4952\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1980 - accuracy: 0.4732 - val_loss: 1.1400 - val_accuracy: 0.4878\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1767 - accuracy: 0.4848 - val_loss: 1.1284 - val_accuracy: 0.4952\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1779 - accuracy: 0.4947 - val_loss: 1.1477 - val_accuracy: 0.4803\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1685 - accuracy: 0.4854 - val_loss: 1.1265 - val_accuracy: 0.4912\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1524 - accuracy: 0.4991 - val_loss: 1.1167 - val_accuracy: 0.4837\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1549 - accuracy: 0.4950 - val_loss: 1.1288 - val_accuracy: 0.4939\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1625 - accuracy: 0.4921 - val_loss: 1.1832 - val_accuracy: 0.4673\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1551 - accuracy: 0.4924 - val_loss: 1.1296 - val_accuracy: 0.4823\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1442 - accuracy: 0.4965 - val_loss: 1.1127 - val_accuracy: 0.5061\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1539 - accuracy: 0.5023 - val_loss: 1.1076 - val_accuracy: 0.5075\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1459 - accuracy: 0.4982 - val_loss: 1.1061 - val_accuracy: 0.5068\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1365 - accuracy: 0.5053 - val_loss: 1.1158 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1339 - accuracy: 0.5067 - val_loss: 1.1336 - val_accuracy: 0.4932\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1371 - accuracy: 0.4956 - val_loss: 1.1170 - val_accuracy: 0.5109\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1160 - accuracy: 0.5193 - val_loss: 1.1210 - val_accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1342 - accuracy: 0.5085 - val_loss: 1.1039 - val_accuracy: 0.5109\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1281 - accuracy: 0.5093 - val_loss: 1.2425 - val_accuracy: 0.4320\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1230 - accuracy: 0.5096 - val_loss: 1.1244 - val_accuracy: 0.5014\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1181 - accuracy: 0.5143 - val_loss: 1.1002 - val_accuracy: 0.5068\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1217 - accuracy: 0.5169 - val_loss: 1.1182 - val_accuracy: 0.5048\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1231 - accuracy: 0.5111 - val_loss: 1.1134 - val_accuracy: 0.4980\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1133 - accuracy: 0.5207 - val_loss: 1.0955 - val_accuracy: 0.5177\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1141 - accuracy: 0.5210 - val_loss: 1.1066 - val_accuracy: 0.5095\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1090 - accuracy: 0.5181 - val_loss: 1.1580 - val_accuracy: 0.4660\n",
            "Epoch 38/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1137 - accuracy: 0.5198 - val_loss: 1.3469 - val_accuracy: 0.3918\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1150 - accuracy: 0.5163 - val_loss: 1.0978 - val_accuracy: 0.5109\n",
            "Epoch 40/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1096 - accuracy: 0.5219 - val_loss: 1.3047 - val_accuracy: 0.4510\n",
            "Epoch 41/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1156 - accuracy: 0.5166 - val_loss: 1.0977 - val_accuracy: 0.5095\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1046 - accuracy: 0.5330 - val_loss: 1.0920 - val_accuracy: 0.5095\n",
            "Epoch 43/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1100 - accuracy: 0.5178 - val_loss: 1.0971 - val_accuracy: 0.5048\n",
            "Epoch 44/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1041 - accuracy: 0.5268 - val_loss: 1.0872 - val_accuracy: 0.5170\n",
            "Epoch 45/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0943 - accuracy: 0.5061 - val_loss: 1.0910 - val_accuracy: 0.5136\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1056 - accuracy: 0.5172 - val_loss: 1.0862 - val_accuracy: 0.5204\n",
            "Epoch 47/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1060 - accuracy: 0.5260 - val_loss: 1.1660 - val_accuracy: 0.4748\n",
            "Epoch 48/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1033 - accuracy: 0.5175 - val_loss: 1.0960 - val_accuracy: 0.5116\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1055 - accuracy: 0.5184 - val_loss: 1.0867 - val_accuracy: 0.5163\n",
            "Epoch 50/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1112 - accuracy: 0.5204 - val_loss: 1.0995 - val_accuracy: 0.5136\n",
            "Epoch 51/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1069 - accuracy: 0.5131 - val_loss: 1.1469 - val_accuracy: 0.4816\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0861 - accuracy: 0.5379 - val_loss: 1.1341 - val_accuracy: 0.4837\n",
            "Epoch 53/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0922 - accuracy: 0.5236 - val_loss: 1.1694 - val_accuracy: 0.4782\n",
            "Epoch 54/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0995 - accuracy: 0.5271 - val_loss: 1.0919 - val_accuracy: 0.5136\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0969 - accuracy: 0.5300 - val_loss: 1.1026 - val_accuracy: 0.5272\n",
            "Epoch 56/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0961 - accuracy: 0.5283 - val_loss: 1.0920 - val_accuracy: 0.5109\n",
            "Epoch 57/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0980 - accuracy: 0.5190 - val_loss: 1.1069 - val_accuracy: 0.5129\n",
            "Epoch 58/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0995 - accuracy: 0.5300 - val_loss: 1.1334 - val_accuracy: 0.4966\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0939 - accuracy: 0.5271 - val_loss: 1.1197 - val_accuracy: 0.5054\n",
            "Epoch 60/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.5271 - val_loss: 1.0885 - val_accuracy: 0.5184\n",
            "Epoch 61/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0921 - accuracy: 0.5335 - val_loss: 1.0869 - val_accuracy: 0.5150\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.5327 - val_loss: 1.0870 - val_accuracy: 0.5245\n",
            "Epoch 63/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1052 - accuracy: 0.5257 - val_loss: 1.1208 - val_accuracy: 0.4959\n",
            "Epoch 64/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0885 - accuracy: 0.5338 - val_loss: 1.0795 - val_accuracy: 0.5156\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0861 - accuracy: 0.5236 - val_loss: 1.1427 - val_accuracy: 0.4871\n",
            "Epoch 66/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0887 - accuracy: 0.5228 - val_loss: 1.2198 - val_accuracy: 0.4884\n",
            "Epoch 67/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0968 - accuracy: 0.5248 - val_loss: 1.1431 - val_accuracy: 0.4857\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0850 - accuracy: 0.5277 - val_loss: 1.0940 - val_accuracy: 0.5218\n",
            "Epoch 69/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0816 - accuracy: 0.5277 - val_loss: 1.0808 - val_accuracy: 0.5299\n",
            "Epoch 70/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0918 - accuracy: 0.5274 - val_loss: 1.1322 - val_accuracy: 0.4905\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0877 - accuracy: 0.5216 - val_loss: 1.1623 - val_accuracy: 0.4837\n",
            "Epoch 72/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0856 - accuracy: 0.5353 - val_loss: 1.2141 - val_accuracy: 0.4707\n",
            "Epoch 73/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0912 - accuracy: 0.5385 - val_loss: 1.5158 - val_accuracy: 0.4204\n",
            "Epoch 74/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0796 - accuracy: 0.5394 - val_loss: 1.0906 - val_accuracy: 0.5190\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0861 - accuracy: 0.5292 - val_loss: 1.0897 - val_accuracy: 0.5095\n",
            "Epoch 76/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0872 - accuracy: 0.5245 - val_loss: 1.0795 - val_accuracy: 0.5286\n",
            "Epoch 77/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0884 - accuracy: 0.5283 - val_loss: 1.1247 - val_accuracy: 0.5109\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0823 - accuracy: 0.5298 - val_loss: 1.0882 - val_accuracy: 0.5150\n",
            "Epoch 79/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0863 - accuracy: 0.5312 - val_loss: 1.2288 - val_accuracy: 0.4762\n",
            "Epoch 80/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0836 - accuracy: 0.5347 - val_loss: 1.1793 - val_accuracy: 0.4803\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0741 - accuracy: 0.5414 - val_loss: 1.4433 - val_accuracy: 0.4218\n",
            "Epoch 82/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0801 - accuracy: 0.5335 - val_loss: 1.0816 - val_accuracy: 0.5177\n",
            "Epoch 83/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0731 - accuracy: 0.5318 - val_loss: 1.0998 - val_accuracy: 0.5156\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0692 - accuracy: 0.5365 - val_loss: 1.1163 - val_accuracy: 0.5007\n",
            "Epoch 85/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0864 - accuracy: 0.5204 - val_loss: 1.0885 - val_accuracy: 0.5095\n",
            "Epoch 86/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0755 - accuracy: 0.5370 - val_loss: 1.0786 - val_accuracy: 0.5259\n",
            "Epoch 87/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0741 - accuracy: 0.5344 - val_loss: 1.0966 - val_accuracy: 0.5184\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0818 - accuracy: 0.5289 - val_loss: 1.2540 - val_accuracy: 0.4721\n",
            "Epoch 89/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0761 - accuracy: 0.5426 - val_loss: 1.0803 - val_accuracy: 0.5190\n",
            "Epoch 90/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0793 - accuracy: 0.5370 - val_loss: 1.2611 - val_accuracy: 0.4748\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0763 - accuracy: 0.5321 - val_loss: 1.1525 - val_accuracy: 0.4878\n",
            "Epoch 92/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0811 - accuracy: 0.5344 - val_loss: 1.1416 - val_accuracy: 0.4782\n",
            "Epoch 93/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0897 - accuracy: 0.5233 - val_loss: 1.0807 - val_accuracy: 0.5136\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0838 - accuracy: 0.5251 - val_loss: 1.0869 - val_accuracy: 0.5252\n",
            "Epoch 95/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0732 - accuracy: 0.5309 - val_loss: 1.0900 - val_accuracy: 0.5204\n",
            "Epoch 96/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0837 - accuracy: 0.5265 - val_loss: 1.1075 - val_accuracy: 0.5082\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0775 - accuracy: 0.5312 - val_loss: 1.0748 - val_accuracy: 0.5197\n",
            "Epoch 98/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0713 - accuracy: 0.5438 - val_loss: 1.0890 - val_accuracy: 0.5177\n",
            "Epoch 99/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0889 - accuracy: 0.5271 - val_loss: 1.1777 - val_accuracy: 0.4789\n",
            "Epoch 100/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0727 - accuracy: 0.5283 - val_loss: 1.0865 - val_accuracy: 0.5150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbk7TjwaZLZj",
        "colab_type": "code",
        "outputId": "eed9e2cd-6740-49a7-cacc-3724d05bcd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#white wine에 대한 테스트\n",
        "results = model.evaluate(white_x_test, new_white_y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 1ms/step - loss: 1.0865 - accuracy: 0.5150\n",
            "Test accuracy:  0.5149660110473633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjB5c3qNP60F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(units=32,input_dim=11,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "\n",
        "model.add(layers.Dense(units=50,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(units=100,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(units=6, activation='softmax'))\n",
        "\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhsAlU_2P7dM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "6cc86da8-e909-4db9-c0c9-4bfeecc61ff6"
      },
      "source": [
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True,\n",
        "    name='Adam'\n",
        ")\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_66 (Dense)             (None, 32)                384       \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 50)                1650      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 6)                 606       \n",
            "=================================================================\n",
            "Total params: 8,468\n",
            "Trainable params: 8,104\n",
            "Non-trainable params: 364\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvIuazgCnWYC",
        "colab_type": "code",
        "outputId": "062333e6-438f-4833-ddc0-1010095e5057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#red_wine에 대한 train\n",
        "new_red_y_train = red_y_train-3\n",
        "new_red_y_test = red_y_test-3\n",
        "history = model.fit(red_x_train, new_red_y_train, batch_size = 10, epochs = 100,validation_data=(red_x_test, new_red_y_test))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['loss'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.5169 - accuracy: 0.2520 - val_loss: 1.4664 - val_accuracy: 0.4437\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.9085 - accuracy: 0.3619 - val_loss: 1.2530 - val_accuracy: 0.5083\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.7422 - accuracy: 0.4066 - val_loss: 1.1678 - val_accuracy: 0.5604\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.5312 - accuracy: 0.4307 - val_loss: 1.1312 - val_accuracy: 0.5437\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.4492 - accuracy: 0.4334 - val_loss: 1.1130 - val_accuracy: 0.5500\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.4332 - accuracy: 0.3995 - val_loss: 1.1206 - val_accuracy: 0.5125\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.4441 - val_loss: 1.0890 - val_accuracy: 0.5562\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2689 - accuracy: 0.4441 - val_loss: 1.0887 - val_accuracy: 0.5375\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2530 - accuracy: 0.4540 - val_loss: 1.0813 - val_accuracy: 0.5604\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2563 - accuracy: 0.4406 - val_loss: 1.0650 - val_accuracy: 0.5708\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2426 - accuracy: 0.4468 - val_loss: 1.0595 - val_accuracy: 0.5750\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1796 - accuracy: 0.4781 - val_loss: 1.0523 - val_accuracy: 0.5833\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.1675 - accuracy: 0.4861 - val_loss: 1.0617 - val_accuracy: 0.5708\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1591 - accuracy: 0.4808 - val_loss: 1.0450 - val_accuracy: 0.5729\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1686 - accuracy: 0.4799 - val_loss: 1.0397 - val_accuracy: 0.5667\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1755 - accuracy: 0.4674 - val_loss: 1.0284 - val_accuracy: 0.5833\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1390 - accuracy: 0.4933 - val_loss: 1.0268 - val_accuracy: 0.5896\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1312 - accuracy: 0.5085 - val_loss: 1.0203 - val_accuracy: 0.5979\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1056 - accuracy: 0.5380 - val_loss: 1.0087 - val_accuracy: 0.5833\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1049 - accuracy: 0.5362 - val_loss: 0.9933 - val_accuracy: 0.5958\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0906 - accuracy: 0.5264 - val_loss: 1.0066 - val_accuracy: 0.5688\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0911 - accuracy: 0.5147 - val_loss: 0.9958 - val_accuracy: 0.5771\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0714 - accuracy: 0.5407 - val_loss: 0.9727 - val_accuracy: 0.6000\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0857 - accuracy: 0.5487 - val_loss: 0.9785 - val_accuracy: 0.6083\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0528 - accuracy: 0.5478 - val_loss: 0.9591 - val_accuracy: 0.5958\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0812 - accuracy: 0.5371 - val_loss: 0.9770 - val_accuracy: 0.6083\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0441 - accuracy: 0.5469 - val_loss: 0.9792 - val_accuracy: 0.5958\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0615 - accuracy: 0.5514 - val_loss: 0.9900 - val_accuracy: 0.5479\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.5737 - val_loss: 0.9508 - val_accuracy: 0.5729\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0390 - accuracy: 0.5416 - val_loss: 0.9531 - val_accuracy: 0.6104\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0558 - accuracy: 0.5362 - val_loss: 0.9448 - val_accuracy: 0.6167\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0525 - accuracy: 0.5469 - val_loss: 0.9407 - val_accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0662 - accuracy: 0.5550 - val_loss: 0.9833 - val_accuracy: 0.5771\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0659 - accuracy: 0.5442 - val_loss: 0.9567 - val_accuracy: 0.6083\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0487 - accuracy: 0.5567 - val_loss: 0.9448 - val_accuracy: 0.5938\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.5460 - val_loss: 0.9414 - val_accuracy: 0.6146\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.5612 - val_loss: 0.9456 - val_accuracy: 0.6125\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.5460 - val_loss: 0.9450 - val_accuracy: 0.6000\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0380 - accuracy: 0.5353 - val_loss: 0.9552 - val_accuracy: 0.5771\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0271 - accuracy: 0.5505 - val_loss: 0.9434 - val_accuracy: 0.6104\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.5621 - val_loss: 0.9416 - val_accuracy: 0.6125\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0321 - accuracy: 0.5523 - val_loss: 0.9720 - val_accuracy: 0.5854\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0329 - accuracy: 0.5657 - val_loss: 0.9603 - val_accuracy: 0.6000\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0141 - accuracy: 0.5559 - val_loss: 0.9347 - val_accuracy: 0.6208\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0427 - accuracy: 0.5344 - val_loss: 0.9616 - val_accuracy: 0.5792\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.5514 - val_loss: 0.9564 - val_accuracy: 0.6083\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0339 - accuracy: 0.5469 - val_loss: 0.9572 - val_accuracy: 0.5938\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0329 - accuracy: 0.5594 - val_loss: 0.9470 - val_accuracy: 0.6042\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0155 - accuracy: 0.5675 - val_loss: 0.9431 - val_accuracy: 0.6167\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0188 - accuracy: 0.5585 - val_loss: 0.9407 - val_accuracy: 0.6250\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0225 - accuracy: 0.5487 - val_loss: 0.9532 - val_accuracy: 0.5938\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0190 - accuracy: 0.5594 - val_loss: 0.9402 - val_accuracy: 0.6250\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0395 - accuracy: 0.5317 - val_loss: 0.9453 - val_accuracy: 0.5917\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0430 - accuracy: 0.5416 - val_loss: 0.9285 - val_accuracy: 0.5979\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0130 - accuracy: 0.5576 - val_loss: 0.9368 - val_accuracy: 0.6062\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0224 - accuracy: 0.5532 - val_loss: 0.9391 - val_accuracy: 0.6208\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0225 - accuracy: 0.5416 - val_loss: 0.9425 - val_accuracy: 0.6208\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.5496 - val_loss: 0.9507 - val_accuracy: 0.6208\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0179 - accuracy: 0.5576 - val_loss: 0.9532 - val_accuracy: 0.6167\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0077 - accuracy: 0.5675 - val_loss: 0.9571 - val_accuracy: 0.5979\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0248 - accuracy: 0.5442 - val_loss: 0.9584 - val_accuracy: 0.5813\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0155 - accuracy: 0.5719 - val_loss: 0.9525 - val_accuracy: 0.6083\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0128 - accuracy: 0.5764 - val_loss: 0.9361 - val_accuracy: 0.6146\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0224 - accuracy: 0.5496 - val_loss: 0.9389 - val_accuracy: 0.6125\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.5773 - val_loss: 0.9590 - val_accuracy: 0.6062\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0299 - accuracy: 0.5469 - val_loss: 0.9454 - val_accuracy: 0.5979\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0117 - accuracy: 0.5639 - val_loss: 0.9291 - val_accuracy: 0.5979\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0190 - accuracy: 0.5648 - val_loss: 0.9387 - val_accuracy: 0.6062\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.5630 - val_loss: 0.9256 - val_accuracy: 0.6146\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.5433 - val_loss: 0.9390 - val_accuracy: 0.6167\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0328 - accuracy: 0.5532 - val_loss: 0.9362 - val_accuracy: 0.6292\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0248 - accuracy: 0.5648 - val_loss: 0.9321 - val_accuracy: 0.6313\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.5567 - val_loss: 0.9258 - val_accuracy: 0.6125\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.5639 - val_loss: 0.9365 - val_accuracy: 0.6187\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.5612 - val_loss: 0.9354 - val_accuracy: 0.6125\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.5460 - val_loss: 0.9637 - val_accuracy: 0.6125\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.5567 - val_loss: 0.9566 - val_accuracy: 0.6083\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9978 - accuracy: 0.5737 - val_loss: 0.9359 - val_accuracy: 0.6208\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9961 - accuracy: 0.5451 - val_loss: 0.9666 - val_accuracy: 0.5979\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9964 - accuracy: 0.5630 - val_loss: 0.9475 - val_accuracy: 0.5938\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0096 - accuracy: 0.5639 - val_loss: 0.9425 - val_accuracy: 0.6187\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.5505 - val_loss: 0.9397 - val_accuracy: 0.6104\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0020 - accuracy: 0.5621 - val_loss: 0.9294 - val_accuracy: 0.6229\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0019 - accuracy: 0.5407 - val_loss: 0.9718 - val_accuracy: 0.5958\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0048 - accuracy: 0.5550 - val_loss: 0.9339 - val_accuracy: 0.5938\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9979 - accuracy: 0.5585 - val_loss: 0.9314 - val_accuracy: 0.6042\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0093 - accuracy: 0.5755 - val_loss: 0.9258 - val_accuracy: 0.5979\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9965 - accuracy: 0.5693 - val_loss: 0.9438 - val_accuracy: 0.6271\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0025 - accuracy: 0.5541 - val_loss: 0.9368 - val_accuracy: 0.6271\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9972 - accuracy: 0.5800 - val_loss: 0.9514 - val_accuracy: 0.6167\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9990 - accuracy: 0.5585 - val_loss: 0.9190 - val_accuracy: 0.6271\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.9982 - accuracy: 0.5487 - val_loss: 0.9394 - val_accuracy: 0.6250\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9994 - accuracy: 0.5505 - val_loss: 0.9311 - val_accuracy: 0.6146\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0263 - accuracy: 0.5424 - val_loss: 0.9535 - val_accuracy: 0.5958\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9974 - accuracy: 0.5719 - val_loss: 0.9458 - val_accuracy: 0.6021\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 1.0124 - accuracy: 0.5675 - val_loss: 0.9261 - val_accuracy: 0.6167\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0129 - accuracy: 0.5603 - val_loss: 0.9276 - val_accuracy: 0.6146\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9935 - accuracy: 0.5702 - val_loss: 0.9404 - val_accuracy: 0.6333\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0069 - accuracy: 0.5505 - val_loss: 0.9287 - val_accuracy: 0.6333\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0091 - accuracy: 0.5362 - val_loss: 0.9279 - val_accuracy: 0.6354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcHKR8tknaWU",
        "colab_type": "code",
        "outputId": "c91955f1-182a-4c9a-cae6-5085bc61547d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#red wine에 대한 테스트\n",
        "results = model.evaluate(red_x_test, new_red_y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 1ms/step - loss: 0.9279 - accuracy: 0.6354\n",
            "Test accuracy:  0.6354166865348816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KJ_KUtH2obWf"
      },
      "source": [
        "### 3. 화이트 와인과 레드 와인을 하나의 모델만 사용하여 분류\n",
        "* 화이트 와인과 레드 와인 데이터를 합쳐 wine 데이터 셋 생성\n",
        "* 입력이 화이트 와인인지 레드 와인인지에 관계없이 와인 품질을 분류하는 모델 생성\n",
        "* 모델의 성능을 향상시킬 수 있는 방법을 찾아 적용할 것\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VWzy7FV8obWg",
        "colab": {}
      },
      "source": [
        "total_wine = pd.concat([white_wine,red_wine])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi-MEhaT1K_Z",
        "colab_type": "code",
        "outputId": "751912b9-b7b8-4bb9-d903-839e4779f316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_wine.shape"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6497, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWXvZZoY7D4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_x_train,total_y_train,total_x_test,total_y_test = generate_data(total_wine, 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P8Vqlz11dVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(units=32,input_dim=11,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "\n",
        "model.add(layers.Dense(units=50,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(units=100,activation='relu'))\n",
        "model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9qfoSC01dwo",
        "colab_type": "code",
        "outputId": "53cae3bd-3d51-4e83-ad9a-80d527e55cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True,\n",
        "    name='Adam'\n",
        ")\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_70 (Dense)             (None, 32)                384       \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 50)                1650      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 7)                 707       \n",
            "=================================================================\n",
            "Total params: 8,569\n",
            "Trainable params: 8,205\n",
            "Non-trainable params: 364\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hat_z0OJ1Lsh",
        "colab_type": "code",
        "outputId": "e07df42a-9ae2-42b6-b013-f30354806018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#total_wine에 대한 train\n",
        "new_total_y_train = total_y_train-3\n",
        "new_total_y_test = total_y_test-3\n",
        "history = model.fit(total_x_train, new_total_y_train, batch_size = 10, epochs = 100)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['loss'], loc = 'upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 2.1313 - accuracy: 0.3020\n",
            "Epoch 2/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.4883 - accuracy: 0.4042\n",
            "Epoch 3/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.2929 - accuracy: 0.4453\n",
            "Epoch 4/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.2298 - accuracy: 0.4656\n",
            "Epoch 5/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1939 - accuracy: 0.4882\n",
            "Epoch 6/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1822 - accuracy: 0.4922\n",
            "Epoch 7/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1774 - accuracy: 0.4913\n",
            "Epoch 8/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1699 - accuracy: 0.4942\n",
            "Epoch 9/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1632 - accuracy: 0.4944\n",
            "Epoch 10/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1530 - accuracy: 0.5082\n",
            "Epoch 11/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1531 - accuracy: 0.4975\n",
            "Epoch 12/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1448 - accuracy: 0.5107\n",
            "Epoch 13/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1478 - accuracy: 0.5063\n",
            "Epoch 14/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1424 - accuracy: 0.5008\n",
            "Epoch 15/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1422 - accuracy: 0.4973\n",
            "Epoch 16/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1394 - accuracy: 0.5058\n",
            "Epoch 17/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1374 - accuracy: 0.5030\n",
            "Epoch 18/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1442 - accuracy: 0.5087\n",
            "Epoch 19/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1408 - accuracy: 0.4990\n",
            "Epoch 20/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1376 - accuracy: 0.4997\n",
            "Epoch 21/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1371 - accuracy: 0.5065\n",
            "Epoch 22/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1322 - accuracy: 0.5060\n",
            "Epoch 23/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1276 - accuracy: 0.5019\n",
            "Epoch 24/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1356 - accuracy: 0.5032\n",
            "Epoch 25/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1306 - accuracy: 0.5076\n",
            "Epoch 26/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1330 - accuracy: 0.5005\n",
            "Epoch 27/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1320 - accuracy: 0.5043\n",
            "Epoch 28/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1327 - accuracy: 0.5027\n",
            "Epoch 29/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1308 - accuracy: 0.5012\n",
            "Epoch 30/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1332 - accuracy: 0.4966\n",
            "Epoch 31/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1225 - accuracy: 0.5041\n",
            "Epoch 32/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1354 - accuracy: 0.5010\n",
            "Epoch 33/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1300 - accuracy: 0.5038\n",
            "Epoch 34/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1254 - accuracy: 0.5041\n",
            "Epoch 35/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1247 - accuracy: 0.5118\n",
            "Epoch 36/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1196 - accuracy: 0.5175\n",
            "Epoch 37/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1248 - accuracy: 0.5056\n",
            "Epoch 38/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1326 - accuracy: 0.5056\n",
            "Epoch 39/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1200 - accuracy: 0.5120\n",
            "Epoch 40/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1237 - accuracy: 0.5089\n",
            "Epoch 41/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1163 - accuracy: 0.5137\n",
            "Epoch 42/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1214 - accuracy: 0.5166\n",
            "Epoch 43/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1198 - accuracy: 0.5071\n",
            "Epoch 44/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1170 - accuracy: 0.5120\n",
            "Epoch 45/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1136 - accuracy: 0.5153\n",
            "Epoch 46/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1229 - accuracy: 0.5093\n",
            "Epoch 47/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1162 - accuracy: 0.5085\n",
            "Epoch 48/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1145 - accuracy: 0.5113\n",
            "Epoch 49/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1216 - accuracy: 0.5126\n",
            "Epoch 50/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1225 - accuracy: 0.5135\n",
            "Epoch 51/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1239 - accuracy: 0.5107\n",
            "Epoch 52/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1229 - accuracy: 0.5034\n",
            "Epoch 53/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1122 - accuracy: 0.5157\n",
            "Epoch 54/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1125 - accuracy: 0.5078\n",
            "Epoch 55/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1229 - accuracy: 0.5153\n",
            "Epoch 56/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1130 - accuracy: 0.5113\n",
            "Epoch 57/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1167 - accuracy: 0.5181\n",
            "Epoch 58/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1150 - accuracy: 0.5179\n",
            "Epoch 59/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1201 - accuracy: 0.5157\n",
            "Epoch 60/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1185 - accuracy: 0.5173\n",
            "Epoch 61/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1167 - accuracy: 0.5122\n",
            "Epoch 62/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1096 - accuracy: 0.5126\n",
            "Epoch 63/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1126 - accuracy: 0.5201\n",
            "Epoch 64/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1236 - accuracy: 0.4990\n",
            "Epoch 65/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1133 - accuracy: 0.5210\n",
            "Epoch 66/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1118 - accuracy: 0.5166\n",
            "Epoch 67/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1192 - accuracy: 0.5063\n",
            "Epoch 68/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1113 - accuracy: 0.5151\n",
            "Epoch 69/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1116 - accuracy: 0.5192\n",
            "Epoch 70/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1122 - accuracy: 0.5085\n",
            "Epoch 71/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1086 - accuracy: 0.5210\n",
            "Epoch 72/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1078 - accuracy: 0.5173\n",
            "Epoch 73/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1096 - accuracy: 0.5195\n",
            "Epoch 74/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1126 - accuracy: 0.5087\n",
            "Epoch 75/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1044 - accuracy: 0.5052\n",
            "Epoch 76/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1188 - accuracy: 0.5034\n",
            "Epoch 77/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1064 - accuracy: 0.5173\n",
            "Epoch 78/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1227 - accuracy: 0.5098\n",
            "Epoch 79/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1133 - accuracy: 0.5190\n",
            "Epoch 80/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1152 - accuracy: 0.5131\n",
            "Epoch 81/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1082 - accuracy: 0.5137\n",
            "Epoch 82/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1118 - accuracy: 0.5091\n",
            "Epoch 83/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1115 - accuracy: 0.5184\n",
            "Epoch 84/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1126 - accuracy: 0.5133\n",
            "Epoch 85/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1047 - accuracy: 0.5206\n",
            "Epoch 86/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1061 - accuracy: 0.5221\n",
            "Epoch 87/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1112 - accuracy: 0.5173\n",
            "Epoch 88/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1119 - accuracy: 0.5175\n",
            "Epoch 89/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1053 - accuracy: 0.5115\n",
            "Epoch 90/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1161 - accuracy: 0.5113\n",
            "Epoch 91/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1041 - accuracy: 0.5170\n",
            "Epoch 92/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1048 - accuracy: 0.5179\n",
            "Epoch 93/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1008 - accuracy: 0.5190\n",
            "Epoch 94/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1183 - accuracy: 0.5199\n",
            "Epoch 95/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1097 - accuracy: 0.5142\n",
            "Epoch 96/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1107 - accuracy: 0.5131\n",
            "Epoch 97/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1054 - accuracy: 0.5179\n",
            "Epoch 98/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1030 - accuracy: 0.5173\n",
            "Epoch 99/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1191 - accuracy: 0.5164\n",
            "Epoch 100/100\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 1.1092 - accuracy: 0.5236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVgUnr91MdW",
        "colab_type": "code",
        "outputId": "6ed70a52-3182-428a-91c0-424645b84e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#total wine에 대한 테스트\n",
        "results = model.evaluate(total_x_test, new_total_y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61/61 [==============================] - 0s 1ms/step - loss: 1.1055 - accuracy: 0.5585\n",
            "Test accuracy:  0.5584615468978882\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}